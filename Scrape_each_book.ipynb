{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import string\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"lexile/raw/lists/\"\n",
    "files = [f for f in glob.glob(path + \"*.html\", recursive=True)]\n",
    "base_url = 'https://www.commonsensemedia.org/book-reviews'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titles(soup):\n",
    "    for s in soup.findAll(class_=\"views-field views-field-field-reference-review-ent-prod result-title\"):\n",
    "        titles.append(s.get_text().strip())\n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_titles(titles):\n",
    "    stripper = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    titles_edited = [t.translate(stripper).replace(\" \", \"-\").lower() for t in titles]\n",
    "    return titles_edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_urls(title_edited):\n",
    "    urls = [base_url + \"/\" + t for t in title_edited]\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "\n",
    "for file in files:\n",
    "    with open(file, 'r') as f: \n",
    "        soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "        get_titles(soup)\n",
    "        \n",
    "titles_edited = edit_titles(titles)\n",
    "\n",
    "urls = make_urls(titles_edited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['title'] = titles\n",
    "df['title_edited'] = titles_edited\n",
    "df['url'] = urls\n",
    "df.loc[:, \"title_edited\"] = df.loc[:, 'title_edited'].str.replace(\"--\", \"-\")\n",
    "df.loc[:, \"url\"] = df.loc[:, \"url\"].str.replace(\"--\", \"-\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Each Book's Review Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir lexile/raw/books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in df.iterrows():\n",
    "    if not os.path.isfile(path + j.title_edited + \".html\"):\n",
    "        page = requests.get(j.url)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        with open(\"lexile/raw/books/\" + j.title_edited + \".html\", 'wb') as f:\n",
    "            try:\n",
    "                f.write(soup.encode('utf-8'))\n",
    "            except:\n",
    "                with open(\"lexile/raw/book-errors.txt\", 'a+') as f:\n",
    "                    f.write(j.title + \"\\n\")\n",
    "    else: \n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
