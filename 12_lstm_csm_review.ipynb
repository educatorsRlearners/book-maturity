{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 665,
     "status": "ok",
     "timestamp": 1586246828418,
     "user": {
      "displayName": "Evan Simpson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p47FxkA9aTnFpdt9dZI0LNlEYYizCC50unaC7Q=s64",
      "userId": "08573321944937795410"
     },
     "user_tz": -120
    },
    "id": "9nn-YIyzJ09Y",
    "outputId": "4b507906-e9cb-4f2d-bf76-fa5c37383048"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rhUo7OzGQl4Z"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from math import sqrt\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, Activation, GlobalMaxPooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2pNg4ay8JZmg"
   },
   "outputs": [],
   "source": [
    "#Run Local\n",
    "#df = pd.read_csv(\"csv/book_info_complete.csv\")\n",
    "#Run on COLAB\n",
    "df = pd.read_csv(\"/content/drive/My Drive/final_project/book_info_complete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1655,
     "status": "ok",
     "timestamp": 1586246869426,
     "user": {
      "displayName": "Evan Simpson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p47FxkA9aTnFpdt9dZI0LNlEYYizCC50unaC7Q=s64",
      "userId": "08573321944937795410"
     },
     "user_tz": -120
    },
    "id": "5hNMh6xrJZmm",
    "outputId": "2576945f-134a-4166-fafd-e3075c253291"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5816 entries, 0 to 5815\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   title             5816 non-null   object\n",
      " 1   description       5816 non-null   object\n",
      " 2   plot              5816 non-null   object\n",
      " 3   csm_review        5816 non-null   object\n",
      " 4   need_to_know      5816 non-null   object\n",
      " 5   csm_rating        5816 non-null   int64 \n",
      " 6   Genre             5816 non-null   object\n",
      " 7   Book type         5816 non-null   object\n",
      " 8   Publication date  5816 non-null   int64 \n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 409.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(axis=1)\n",
    "df[\"Publication date\"] = df[\"Publication date\"].str[-4:].astype(int)\n",
    "df = df.drop(\"Last updated\", axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V7b04dMoJZms"
   },
   "outputs": [],
   "source": [
    "#df[\"text\"] = df['title'] + \" \" + df['plot'] + \" \" + df[\"description\"] + \" \" + df[\"csm_review\"] + \" \" + df[\"need_to_know\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a1RnxUyXJZmx"
   },
   "source": [
    "## Create the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M0_-59xOJZmy"
   },
   "outputs": [],
   "source": [
    "def splitter(df):\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=999)\n",
    "    for train_index, test_index in split.split(df, df['csm_rating']):\n",
    "        train_data= df.loc[train_index]\n",
    "        test_data = df.loc[test_index]\n",
    "    \n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3wkFIijOJZm4"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = splitter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YjI0Lfc8JZm9"
   },
   "outputs": [],
   "source": [
    "x_tr, y_tr = train_data['csm_review'].values, train_data[\"csm_rating\"].values\n",
    "x_val, y_val = test_data[\"csm_review\"].values, test_data[\"csm_rating\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1416,
     "status": "ok",
     "timestamp": 1586246886679,
     "user": {
      "displayName": "Evan Simpson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p47FxkA9aTnFpdt9dZI0LNlEYYizCC50unaC7Q=s64",
      "userId": "08573321944937795410"
     },
     "user_tz": -120
    },
    "id": "64omNypEJZnC",
    "outputId": "a15d902a-b008-4cf5-fdff-81f85474fa6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4652,) (4652,)\n"
     ]
    }
   ],
   "source": [
    "print(x_tr.shape, y_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 873,
     "status": "ok",
     "timestamp": 1586246888082,
     "user": {
      "displayName": "Evan Simpson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p47FxkA9aTnFpdt9dZI0LNlEYYizCC50unaC7Q=s64",
      "userId": "08573321944937795410"
     },
     "user_tz": -120
    },
    "id": "6SCDNHa2JZnJ",
    "outputId": "c9b2f97d-4a48-4a0e-d1ae-29f898216aac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1164,) (1164,)\n"
     ]
    }
   ],
   "source": [
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z1CH5m22JZnO"
   },
   "source": [
    "## Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1446,
     "status": "ok",
     "timestamp": 1586246893502,
     "user": {
      "displayName": "Evan Simpson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p47FxkA9aTnFpdt9dZI0LNlEYYizCC50unaC7Q=s64",
      "userId": "08573321944937795410"
     },
     "user_tz": -120
    },
    "id": "liitdrp9JZnP",
    "outputId": "cb4212f9-15dd-454c-fa61-467557e8fd54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "#Tokenize the sentences\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "#preparing vocabulary\n",
    "tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#converting text into integer sequences\n",
    "x_tr_seq  = tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq = tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "print(len(max(x_tr_seq, key=len)))\n",
    "max_length = len(max(x_tr_seq, key=len))\n",
    "print(len(min(x_tr_seq, key=len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 639,
     "status": "ok",
     "timestamp": 1586246894426,
     "user": {
      "displayName": "Evan Simpson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p47FxkA9aTnFpdt9dZI0LNlEYYizCC50unaC7Q=s64",
      "userId": "08573321944937795410"
     },
     "user_tz": -120
    },
    "id": "nGP4OL9XJZnT",
    "outputId": "d3f1d43d-6cdc-453d-9532-b9803fe2f319"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502\n",
      "502\n"
     ]
    }
   ],
   "source": [
    "#padding to prepare sequences of same length\n",
    "x_tr_seq  = pad_sequences(x_tr_seq, maxlen=max_length)\n",
    "x_val_seq = pad_sequences(x_val_seq, maxlen=max_length)\n",
    "print(len(max(x_tr_seq, key=len)))\n",
    "print(len(min(x_tr_seq, key=len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 667,
     "status": "ok",
     "timestamp": 1586246895958,
     "user": {
      "displayName": "Evan Simpson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p47FxkA9aTnFpdt9dZI0LNlEYYizCC50unaC7Q=s64",
      "userId": "08573321944937795410"
     },
     "user_tz": -120
    },
    "id": "NuoM9u8HJZnZ",
    "outputId": "54ad2d57-4b04-46c2-823a-d1aefccacb8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30700\n"
     ]
    }
   ],
   "source": [
    "size_of_vocabulary=len(tokenizer.word_index) + 1 #+1 for padding\n",
    "print(size_of_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ThBDgrP8JZnf"
   },
   "source": [
    "## Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 654,
     "status": "ok",
     "timestamp": 1586246900588,
     "user": {
      "displayName": "Evan Simpson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p47FxkA9aTnFpdt9dZI0LNlEYYizCC50unaC7Q=s64",
      "userId": "08573321944937795410"
     },
     "user_tz": -120
    },
    "id": "VdR43fJQJZng",
    "outputId": "9ea4131e-2672-4f18-d403-3ebcac4f3d77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30699 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print(\"Found %s unique tokens.\" % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uF9AT0LdJZnl"
   },
   "source": [
    "## Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8086,
     "status": "ok",
     "timestamp": 1586246930056,
     "user": {
      "displayName": "Evan Simpson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p47FxkA9aTnFpdt9dZI0LNlEYYizCC50unaC7Q=s64",
      "userId": "08573321944937795410"
     },
     "user_tz": -120
    },
    "id": "aUdRk0UDJZnl",
    "outputId": "1436fcdf-1dc4-42ad-adbb-42df01c2a389"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 502, 300)          9210000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 502, 128)          219648    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 9,437,969\n",
      "Trainable params: 9,437,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "#embedding layer\n",
    "model.add(Embedding(size_of_vocabulary,300,input_length=max_length,trainable=True)) \n",
    "\n",
    "#lstm layer\n",
    "model.add(LSTM(128,return_sequences=True,dropout=0.2))\n",
    "\n",
    "#Global Maxpooling\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "#Dense Layer\n",
    "model.add(Dense(64,activation='relu')) \n",
    "model.add(Dense(1,activation='relu')) \n",
    "\n",
    "#Add loss function, metrics, optimizer\n",
    "#optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "model.compile(optimizer=\"RMSprop\", loss='mean_squared_error', metrics=[\"mae\"]) \n",
    "\n",
    "#Print summary of model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hKZo_lzaJZnr"
   },
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kl98dyhkJZns"
   },
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(patience=10)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_mae', \n",
    "                                            patience=2, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "callbacks = [earlystop, learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "op3MuPCKJZnx"
   },
   "source": [
    "## Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 941
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 128636,
     "status": "ok",
     "timestamp": 1586247071206,
     "user": {
      "displayName": "Evan Simpson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p47FxkA9aTnFpdt9dZI0LNlEYYizCC50unaC7Q=s64",
      "userId": "08573321944937795410"
     },
     "user_tz": -120
    },
    "id": "_I34WFwPJZny",
    "outputId": "35a39bff-b2ed-4b7a-ea2d-7343aaa5e071"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "37/37 [==============================] - 6s 167ms/step - loss: 23.8846 - mae: 3.9629 - val_loss: 15.2217 - val_mae: 3.3077 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 6s 151ms/step - loss: 15.1336 - mae: 3.2852 - val_loss: 14.8669 - val_mae: 3.2701 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 6s 153ms/step - loss: 13.5917 - mae: 3.1083 - val_loss: 12.3484 - val_mae: 2.9404 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 6s 151ms/step - loss: 10.0877 - mae: 2.6761 - val_loss: 8.9303 - val_mae: 2.4490 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 6s 151ms/step - loss: 6.7190 - mae: 2.1270 - val_loss: 7.1058 - val_mae: 2.0478 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 6s 152ms/step - loss: 5.0808 - mae: 1.7859 - val_loss: 6.7963 - val_mae: 1.9484 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 6s 150ms/step - loss: 4.2072 - mae: 1.5926 - val_loss: 5.2441 - val_mae: 1.7905 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 6s 149ms/step - loss: 3.3002 - mae: 1.3943 - val_loss: 5.4067 - val_mae: 1.7589 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 6s 149ms/step - loss: 2.6667 - mae: 1.2531 - val_loss: 5.0190 - val_mae: 1.7009 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 6s 150ms/step - loss: 2.1384 - mae: 1.1026 - val_loss: 6.6597 - val_mae: 2.0781 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.8279 - mae: 1.0171\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "37/37 [==============================] - 6s 151ms/step - loss: 1.8279 - mae: 1.0171 - val_loss: 4.8714 - val_mae: 1.7016 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - 6s 152ms/step - loss: 1.1569 - mae: 0.7951 - val_loss: 4.9198 - val_mae: 1.7058 - lr: 5.0000e-04\n",
      "Epoch 13/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.9738 - mae: 0.7162\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "37/37 [==============================] - 6s 151ms/step - loss: 0.9738 - mae: 0.7162 - val_loss: 5.9342 - val_mae: 1.8342 - lr: 5.0000e-04\n",
      "Epoch 14/1000\n",
      "37/37 [==============================] - 6s 150ms/step - loss: 0.7130 - mae: 0.5968 - val_loss: 4.8970 - val_mae: 1.6814 - lr: 2.5000e-04\n",
      "Epoch 15/1000\n",
      "37/37 [==============================] - 6s 150ms/step - loss: 0.6326 - mae: 0.5538 - val_loss: 5.0044 - val_mae: 1.6846 - lr: 2.5000e-04\n",
      "Epoch 16/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.5511 - mae: 0.5145\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "37/37 [==============================] - 6s 151ms/step - loss: 0.5511 - mae: 0.5145 - val_loss: 4.9790 - val_mae: 1.7023 - lr: 2.5000e-04\n",
      "Epoch 17/1000\n",
      "37/37 [==============================] - 6s 150ms/step - loss: 0.4469 - mae: 0.4493 - val_loss: 5.0390 - val_mae: 1.7235 - lr: 1.2500e-04\n",
      "Epoch 18/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.4116 - mae: 0.4260\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "37/37 [==============================] - 6s 153ms/step - loss: 0.4116 - mae: 0.4260 - val_loss: 4.9263 - val_mae: 1.6856 - lr: 1.2500e-04\n",
      "Epoch 19/1000\n",
      "37/37 [==============================] - 6s 153ms/step - loss: 0.3713 - mae: 0.3986 - val_loss: 4.9098 - val_mae: 1.6822 - lr: 6.2500e-05\n",
      "Epoch 20/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3556 - mae: 0.3879\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "37/37 [==============================] - 6s 150ms/step - loss: 0.3556 - mae: 0.3879 - val_loss: 4.9512 - val_mae: 1.6816 - lr: 6.2500e-05\n",
      "Epoch 21/1000\n",
      "37/37 [==============================] - 6s 149ms/step - loss: 0.3286 - mae: 0.3700 - val_loss: 4.9186 - val_mae: 1.6826 - lr: 3.1250e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(np.array(x_tr_seq),\n",
    "                    np.array(y_tr),\n",
    "                    batch_size=128,\n",
    "                    epochs=1000,\n",
    "                    validation_data=(np.array(x_val_seq),np.array(y_val)),\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1260,
     "status": "ok",
     "timestamp": 1586247189939,
     "user": {
      "displayName": "Evan Simpson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p47FxkA9aTnFpdt9dZI0LNlEYYizCC50unaC7Q=s64",
      "userId": "08573321944937795410"
     },
     "user_tz": -120
    },
    "id": "ojMu-A3wJZn4",
    "outputId": "2fe105eb-4919-45c1-a1c5-1b402af9400e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 18ms/step - loss: 4.7706 - mae: 1.6826\n",
      "The val_mae is 1.683.\n"
     ]
    }
   ],
   "source": [
    "#evaluation \n",
    "val_loss, val_mae = model.evaluate(x_val_seq, y_val)\n",
    "\n",
    "print(\"The val_mae is %.3f.\" % val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 675,
     "status": "error",
     "timestamp": 1586247208238,
     "user": {
      "displayName": "Evan Simpson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p47FxkA9aTnFpdt9dZI0LNlEYYizCC50unaC7Q=s64",
      "userId": "08573321944937795410"
     },
     "user_tz": -120
    },
    "id": "QX82za-8JZn_",
    "outputId": "7ab47f06-a9df-4c49-fc0f-35efb91eca81"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-b9d575144017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'loss'"
     ]
    }
   ],
   "source": [
    "plt.plot(model.history.history[\"loss\"], label=\"loss\");\n",
    "plt.plot(model.history.history[\"val_loss\"], label=\"val_loss\");\n",
    "plt.legend();\n",
    "plt.show();\n",
    "plt.close();\n",
    "\n",
    "plt.plot(model.history.history[\"mae\"], label=\"mae\");\n",
    "plt.plot(model.history.history[\"val_mae\"], label=\"val_mae\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QSOY8AH2JZoF"
   },
   "source": [
    "## [Use Transfer Learning](https://www.analyticsvidhya.com/blog/2020/03/pretrained-word-embeddings-nlp/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32485,
     "status": "ok",
     "timestamp": 1586247298377,
     "user": {
      "displayName": "Evan Simpson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p47FxkA9aTnFpdt9dZI0LNlEYYizCC50unaC7Q=s64",
      "userId": "08573321944937795410"
     },
     "user_tz": -120
    },
    "id": "GdKeDrv9JZoG",
    "outputId": "7fab4bf7-54e6-4aca-af25-40c43989f51a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "\n",
    "with open(\"/content/drive/My Drive/Colab Notebooks/glove.6B/glove.6B.300d.txt\") as f:\n",
    "\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dJqtmI0pJZoL"
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((size_of_vocabulary, 300))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 717,
     "status": "ok",
     "timestamp": 1586247303605,
     "user": {
      "displayName": "Evan Simpson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p47FxkA9aTnFpdt9dZI0LNlEYYizCC50unaC7Q=s64",
      "userId": "08573321944937795410"
     },
     "user_tz": -120
    },
    "id": "NGM-hGE4JZoQ",
    "outputId": "b3ee878c-1fac-405c-e57f-535a1d435531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 502, 300)          9210000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 502, 128)          219648    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 9,437,969\n",
      "Trainable params: 9,437,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model2=Sequential()\n",
    "\n",
    "#embedding layer\n",
    "model2.add(Embedding(size_of_vocabulary,300,input_length=max_length,trainable=True)) \n",
    "\n",
    "#lstm layer\n",
    "model2.add(LSTM(128,return_sequences=True,dropout=0.2))\n",
    "\n",
    "#Global Maxpooling\n",
    "model2.add(GlobalMaxPooling1D())\n",
    "\n",
    "#Dense Layer\n",
    "model2.add(Dense(64,activation='relu')) \n",
    "model2.add(Dense(1,activation='relu')) \n",
    "\n",
    "#Add loss function, metrics, optimizer\n",
    "#optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "model2.compile(optimizer=\"RMSprop\", loss='mean_squared_error', metrics=[\"mae\"]) \n",
    "\n",
    "#Print summary of model\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 976
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 124297,
     "status": "ok",
     "timestamp": 1586247428969,
     "user": {
      "displayName": "Evan Simpson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p47FxkA9aTnFpdt9dZI0LNlEYYizCC50unaC7Q=s64",
      "userId": "08573321944937795410"
     },
     "user_tz": -120
    },
    "id": "o4IlOKDvJZoU",
    "outputId": "c11fdcc7-8d67-435a-9280-9c500cae0725"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "37/37 [==============================] - 6s 162ms/step - loss: 23.7724 - mae: 3.9680 - val_loss: 15.4418 - val_mae: 3.3052 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 6s 151ms/step - loss: 14.8373 - mae: 3.2595 - val_loss: 14.2261 - val_mae: 3.1865 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 6s 155ms/step - loss: 13.0930 - mae: 3.0567 - val_loss: 12.3030 - val_mae: 2.9578 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 6s 153ms/step - loss: 10.2579 - mae: 2.6864 - val_loss: 8.8424 - val_mae: 2.4816 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 6s 153ms/step - loss: 7.1606 - mae: 2.1961 - val_loss: 6.5234 - val_mae: 2.0599 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 6s 154ms/step - loss: 5.1792 - mae: 1.8175 - val_loss: 5.8048 - val_mae: 1.9147 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 6s 153ms/step - loss: 4.1118 - mae: 1.5719 - val_loss: 5.2195 - val_mae: 1.7313 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 6s 154ms/step - loss: 3.2567 - mae: 1.3932 - val_loss: 6.1783 - val_mae: 1.8432 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 2.7839 - mae: 1.2688\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "37/37 [==============================] - 6s 153ms/step - loss: 2.7839 - mae: 1.2688 - val_loss: 8.0086 - val_mae: 2.1194 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 6s 152ms/step - loss: 1.8279 - mae: 1.0163 - val_loss: 5.2529 - val_mae: 1.6939 - lr: 5.0000e-04\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - 6s 152ms/step - loss: 1.5560 - mae: 0.9385 - val_loss: 5.0138 - val_mae: 1.6805 - lr: 5.0000e-04\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - 6s 151ms/step - loss: 1.3270 - mae: 0.8623 - val_loss: 5.3659 - val_mae: 1.7721 - lr: 5.0000e-04\n",
      "Epoch 13/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.1835 - mae: 0.8110\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "37/37 [==============================] - 6s 155ms/step - loss: 1.1835 - mae: 0.8110 - val_loss: 5.2764 - val_mae: 1.7319 - lr: 5.0000e-04\n",
      "Epoch 14/1000\n",
      "37/37 [==============================] - 6s 153ms/step - loss: 0.8378 - mae: 0.6602 - val_loss: 5.2110 - val_mae: 1.7064 - lr: 2.5000e-04\n",
      "Epoch 15/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.7813 - mae: 0.6373\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "37/37 [==============================] - 6s 153ms/step - loss: 0.7813 - mae: 0.6373 - val_loss: 5.2903 - val_mae: 1.7004 - lr: 2.5000e-04\n",
      "Epoch 16/1000\n",
      "37/37 [==============================] - 6s 153ms/step - loss: 0.6333 - mae: 0.5575 - val_loss: 5.2010 - val_mae: 1.7015 - lr: 1.2500e-04\n",
      "Epoch 17/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.5950 - mae: 0.5305\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "37/37 [==============================] - 6s 152ms/step - loss: 0.5950 - mae: 0.5305 - val_loss: 5.3060 - val_mae: 1.7035 - lr: 1.2500e-04\n",
      "Epoch 18/1000\n",
      "37/37 [==============================] - 6s 153ms/step - loss: 0.5324 - mae: 0.4976 - val_loss: 5.2711 - val_mae: 1.7218 - lr: 6.2500e-05\n",
      "Epoch 19/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.5145 - mae: 0.4875\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "37/37 [==============================] - 6s 153ms/step - loss: 0.5145 - mae: 0.4875 - val_loss: 5.2789 - val_mae: 1.7286 - lr: 6.2500e-05\n",
      "Epoch 20/1000\n",
      "37/37 [==============================] - 6s 151ms/step - loss: 0.4884 - mae: 0.4707 - val_loss: 5.2496 - val_mae: 1.7055 - lr: 3.1250e-05\n",
      "Epoch 21/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.4843 - mae: 0.4681\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "37/37 [==============================] - 6s 152ms/step - loss: 0.4843 - mae: 0.4681 - val_loss: 5.2622 - val_mae: 1.7202 - lr: 3.1250e-05\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(np.array(x_tr_seq),\n",
    "                    np.array(y_tr),\n",
    "                    batch_size=128,\n",
    "                    epochs=1000,\n",
    "                    validation_data=(np.array(x_val_seq),np.array(y_val)),\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1405,
     "status": "ok",
     "timestamp": 1586247437039,
     "user": {
      "displayName": "Evan Simpson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p47FxkA9aTnFpdt9dZI0LNlEYYizCC50unaC7Q=s64",
      "userId": "08573321944937795410"
     },
     "user_tz": -120
    },
    "id": "88gF08odJZoY",
    "outputId": "1b24076e-a962-401c-e727-a679883e4a81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 19ms/step - loss: 4.9926 - mae: 1.7202\n",
      "The val_mae is 1.720.\n"
     ]
    }
   ],
   "source": [
    "#evaluation \n",
    "_, val_mae = model2.evaluate(x_val_seq, y_val)\n",
    "\n",
    "print(\"The val_mae is %.3f.\" % val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4330,
     "status": "error",
     "timestamp": 1586247463883,
     "user": {
      "displayName": "Evan Simpson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p47FxkA9aTnFpdt9dZI0LNlEYYizCC50unaC7Q=s64",
      "userId": "08573321944937795410"
     },
     "user_tz": -120
    },
    "id": "VjHaGr87fXHA",
    "outputId": "ba17c6fe-1803-4b4f-ca80-e989fb3b5dda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-d3fc4fe9f234>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/final_project/lstm_csm_review_transfer_model_scaled'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \"\"\"\n\u001b[1;32m   1046\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 1047\u001b[0;31m                     signatures, options)\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    136\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[0;32m--> 138\u001b[0;31m                           signatures, options)\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(model, filepath, overwrite, include_optimizer, signatures, options)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# we use the default replica context here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_default_replica_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m       \u001b[0msave_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m    954\u001b[0m   \u001b[0;31m# Write the checkpoint, copy assets into the assets directory, and write out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m   \u001b[0;31m# the SavedModel proto itself.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m   \u001b[0mutils_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_or_create_variables_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m   \u001b[0mobject_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m   builder_impl.copy_assets_to_destination_dir(asset_info.asset_filename_map,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/utils_impl.py\u001b[0m in \u001b[0;36mget_or_create_variables_dir\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    212\u001b[0m   \u001b[0mvariables_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_variables_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mvariables_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mrecursive_create_dir\u001b[0;34m(dirname)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m   \"\"\"\n\u001b[0;32m--> 427\u001b[0;31m   \u001b[0mrecursive_create_dir_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mrecursive_create_dir_v2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m   \"\"\"\n\u001b[0;32m--> 442\u001b[0;31m   \u001b[0m_pywrap_file_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecursivelyCreateDir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: /content/drive/My Drive/final_project/lstm_csm_review_transfer_model_scaled is not a directory"
     ]
    }
   ],
   "source": [
    "model2.save('/content/drive/My Drive/final_project/lstm_csm_review_transfer_model_scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 796,
     "status": "error",
     "timestamp": 1586247497939,
     "user": {
      "displayName": "Evan Simpson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4p47FxkA9aTnFpdt9dZI0LNlEYYizCC50unaC7Q=s64",
      "userId": "08573321944937795410"
     },
     "user_tz": -120
    },
    "id": "FY3cjzn3JZoe",
    "outputId": "7765fed1-89d8-46ba-9137-3eb99e2140ce"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-3bad321a086e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'loss'"
     ]
    }
   ],
   "source": [
    "plt.plot(model2.history.history[\"loss\"], label=\"loss\");\n",
    "plt.plot(model2.history.history[\"val_loss\"], label=\"val_loss\");\n",
    "plt.legend();\n",
    "plt.show();\n",
    "plt.close();\n",
    "\n",
    "plt.plot(model2.history.history[\"mae\"], label=\"mae\");\n",
    "plt.plot(model2.history.history[\"val_mae\"], label=\"val_mae\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3wPhkh6PPdSa"
   },
   "outputs": [],
   "source": [
    "a = model2.predict(x_val_seq)\n",
    "b = model2.predict(x_val_seq)\n",
    "#a = min_max_scaler_target.inverse_transform(a)\n",
    "#b = min_max_scaler_target.inverse_transform(b)\n",
    "\n",
    "csm_lstm_predictions_df = pd.DataFrame({\"csm_custom\": list(a), \"csm_transfer\": list(b)},\n",
    "                              columns = [\"csm_custom\", \"csm_transfer\"], \n",
    "                              index=test_data.index)\n",
    "\n",
    "csm_lstm_predictions_df.to_csv('/content/drive/My Drive/final_project/lstm_csm_review.csv', index=\"False\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pfxICpfWuCpB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "12_lstm_csm_review.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
