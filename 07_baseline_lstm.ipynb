{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4651 entries, 0 to 4650\n",
      "Data columns (total 24 columns):\n",
      "title                             4651 non-null object\n",
      "description                       4651 non-null object\n",
      "plot                              4651 non-null object\n",
      "csm_review                        4651 non-null object\n",
      "need_to_know                      4651 non-null object\n",
      "par_rating                        1988 non-null float64\n",
      "kids_rating                       2413 non-null float64\n",
      "csm_rating                        4651 non-null int64\n",
      "Author                            4376 non-null object\n",
      "Genre                             4651 non-null object\n",
      "Topics                            3112 non-null object\n",
      "Book type                         4651 non-null object\n",
      "Publisher                         4545 non-null object\n",
      "Publication date                  4651 non-null object\n",
      "Publisher's recommended age(s)    3725 non-null object\n",
      "Number of pages                   4615 non-null float64\n",
      "Available on                      2853 non-null object\n",
      "Last updated                      4651 non-null object\n",
      "Illustrator                       2007 non-null object\n",
      "Authors                           275 non-null object\n",
      "Awards                            55 non-null object\n",
      "Publishers                        26 non-null object\n",
      "Award                             331 non-null object\n",
      "Illustrators                      46 non-null object\n",
      "dtypes: float64(3), int64(1), object(20)\n",
      "memory usage: 872.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('csv/train.csv')\n",
    "test = pd.read_csv(\"csv/test.csv\")\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, y_tr = train['description'].values, train['csm_rating'].values\n",
    "x_test, y_test = test[\"description\"].values, test[\"csm_rating\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4651,) (4651,)\n"
     ]
    }
   ],
   "source": [
    "print(x_tr.shape, y_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1164,) (1164,)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize the sentences\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "#preparing vocabulary\n",
    "tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#converting text into integer sequences\n",
    "x_tr_seq  = tokenizer.texts_to_sequences(x_tr) \n",
    "x_test_seq = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5814 unique tokesn.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print(\"Found %s unique tokens.\" % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use prepading for the max length as denoted [here](https://arxiv.org/pdf/1903.07288.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(max(x_tr_seq, key=len)))\n",
    "print(len(min(x_tr_seq, key=len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding to prepare sequences of same length\n",
    "x_tr_seq  = pad_sequences(x_tr_seq, maxlen=14)\n",
    "x_test_seq = pad_sequences(x_test_seq, maxlen=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(max(x_tr_seq, key=len)))\n",
    "print(len(min(x_tr_seq, key=len)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5815\n"
     ]
    }
   ],
   "source": [
    "size_of_vocabulary=len(tokenizer.word_index) + 1 #+1 for padding\n",
    "print(size_of_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deep learning library\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "\n",
    "#embedding layer\n",
    "model.add(Embedding(size_of_vocabulary,300,input_length=100,trainable=True)) \n",
    "\n",
    "#lstm layer\n",
    "model.add(LSTM(128,return_sequences=True,dropout=0.2))\n",
    "\n",
    "#Global Maxpooling\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "#Dense Layer\n",
    "model.add(Dense(64,activation='relu')) \n",
    "model.add(Dense(1,activation='sigmoid')) \n",
    "\n",
    "#Add loss function, metrics, optimizer\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=[\"acc\"]) \n",
    "\n",
    "#Adding callbacks\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \n",
    "mc=ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', save_best_only=True,verbose=1)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
